##### REFERENCES#######
# I refered to tensorflows documentation to help aim me with implementing tf modules
# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator
# https://www.tensorflow.org/api_docs/python/tf/keras

# DATASET: Ghazaei, G; Nazarpour, K (2017): Newcastle Grasp Library. Newcastle University. Dataset. 
# https://doi.org/10.17634/141353-1@ https://data.ncl.ac.uk/articles/dataset/Newcastle_Grasp_Library/10280804/1
# DATASET: I shuffled and split the dataset myself with python code. 

import tensorflow as tf
from tensorflow.keras.applications import VGG19
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model


                                                           

train_data_path = 'train_data'
test_data_path = 'test_data'

num_classes = 4                                               
input_size = (224, 224)                                   
learning_rate = 0.001                                       
num_batch = 32                                                 
num_epochs = 1                                                

base_model = VGG19(include_top=False, 
    weights='imagenet', 
    input_shape=(input_size[0], 
    input_size[1], 3))




base_output = base_model.output    
pooled_features = GlobalAveragePooling2D()(base_output)    
hidden_features = Dense(256, activation='relu')(pooled_features)
predictions = Dense(num_classes, activation='softmax')(hidden_features) 
model = Model(inputs=base_model.input, outputs=predictions) 
for layer in base_model.layers: 
    layer.trainable = False 
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])

train_dataGen = ImageDataGenerator(  
    rotation_range=20,   
    width_shift_range=0.2, 
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
    shear_range=0.2,
    zoom_range = 0.2
)

train_gen = train_dataGen.flow_from_directory(
    train_data_path,
    target_size=input_size,
    batch_size=num_batch,
    class_mode='categorical',
    subset='training'
)

validation_gen = train_dataGen.flow_from_directory(
    train_data_path,
    target_size=input_size,
    batch_size=num_batch,
    class_mode='categorical',
    subset='validation'
)


test_dataGen = ImageDataGenerator(rescale=1./255) 
test_gen = test_dataGen.flow_from_directory(
    test_data_path,
    target_size=input_size,
    batch_size=num_batch,
    class_mode='categorical'
)

model.fit(
    train_gen,
    steps_per_epoch=train_gen.samples // num_batch,
    epochs=num_epochs,
    validation_data=validation_gen,
    validation_steps=validation_gen.samples // num_batch
)

loss, accuracy = model.evaluate(test_gen)
print('Test Loss:', loss) 
print('Test Accuracy:', accuracy) 

model.save('VGG19_model.h5') 